{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import arange\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from func_autograd import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def MSE(y_data, y_model):\n",
    "\tn = np.size(y_model)\n",
    "\ty_data = y_data.reshape(-1,1)\n",
    "\ty_model = y_model.reshape(-1,1)\n",
    "\treturn np.sum((y_data - y_model)**2)/n\n",
    "\n",
    "\n",
    "def generate_data(noise=True, step_size=0.05 , FrankesFunction=True):\n",
    "    # Arrange x and y\n",
    "    x = np.arange(0, 1, step_size)\n",
    "    y = np.arange(0, 1, step_size)\n",
    "    # Create meshgrid of x and y\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    if FrankesFunction:\n",
    "        # Calculate the values for Franke function\n",
    "        z = FrankeFunction(X, Y, noise=noise).flatten()\n",
    "    else:\n",
    "        z = TestFunction(X, Y, noise=noise).flatten()\n",
    "\n",
    "    # Flatten x and y for plotting\n",
    "    x = X.flatten()\n",
    "    y = Y.flatten()\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "def TestFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "\n",
    "    return  x**2 + y**2 + 2*x*y + random_noise\n",
    "\n",
    "def FrankeFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "    \n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + random_noise\n",
    "\n",
    "x, y, z = generate_data()\n",
    "X = create_X(x, y, 7)\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd: learning rate and minimal train MSE\n",
      "0.07800000000000001 0.21239183827522068\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.1 0.25 0.19463814788879574\n",
      "gd: learning rate and minimal train MSE\n",
      "0.001 0.1994109344156838\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.067 0.25 0.19296293237444687\n",
      "gd: learning rate and minimal train MSE\n",
      "0.012 0.2522201841012957\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.012 0.5 0.1998516160912237\n",
      "gd: learning rate and minimal train MSE\n",
      "0.012 0.20247244974048922\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.045000000000000005 0.3 0.1929014121801626\n",
      "gd: learning rate and minimal train MSE\n",
      "0.1 0.228224212595669\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.023000000000000003 0.25 0.1949698963266102\n",
      "gd: learning rate and minimal train MSE\n",
      "0.012 0.3498085559952122\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.1 0.35000000000000003 0.19314903569639588\n",
      "gd: learning rate and minimal train MSE\n",
      "0.1 0.19463087748888255\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.001 0.3 0.1936816723049215\n",
      "gd: learning rate and minimal train MSE\n",
      "0.067 0.23954842255885894\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.08900000000000001 0.2 0.19439846181276718\n",
      "gd: learning rate and minimal train MSE\n",
      "0.034 0.2030275140162497\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.001 0.2 0.19451822718223644\n",
      "gd: learning rate and minimal train MSE\n",
      "0.023000000000000003 0.20548260671958274\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.001 0.1 0.19439701765177722\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "gamma = np.linspace(0.001, 0.1, 10)\n",
    "delta = np.linspace(0.05, 0.5, 10)\n",
    "eta = np.linspace(0.7, 0.95, 5)\n",
    "\n",
    "X_train = X_train[:, 1:3]\n",
    "X_test = X_test[:, 1:3]\n",
    "\n",
    "trials = 10\n",
    "\n",
    "gd_gamma = np.zeros(len(gamma))\n",
    "gd_mom_gamma = np.zeros(len(gamma))\n",
    "gd_mom_delta = np.zeros(len(delta))\n",
    "\n",
    "for t in range(trials):\n",
    "    initial_val = np.random.randn(X_train.shape[1],1)\n",
    "\n",
    "    # plain gradient descent\n",
    "    train_score = np.zeros(len(gamma))\n",
    "    for i in range(len(gamma)):\n",
    "        model = GradientDescend(momentum=False, learning_rate=gamma[i])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[i] = MSE(pred_train, z_train)\n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    gd_gamma[i_min] += 1\n",
    "    print(\"gd: learning rate and minimal train MSE\")\n",
    "    print(gamma[i_min], min)\n",
    "\n",
    "    # adding momentum\n",
    "    train_score = np.zeros((len(gamma), len(delta)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            model = GradientDescend(learning_rate=gamma[i], delta_momentum=delta[j])\n",
    "            scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "            pred_train = model.predict(X_train)\n",
    "            train_score[i, j] = MSE(pred_train, z_train)\n",
    "        \n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l])\n",
    "    gd_mom_gamma[i_min[0]] += 1\n",
    "    gd_mom_delta[i_min[1]] += 1\n",
    "    print(\"gd with momentum: learning rate, momentum and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], min)\n",
    "\n",
    "\n",
    "gd_gamma_opt = gamma[gd_gamma.argmax()]\n",
    "gd_mom_gamma_opt = gamma[gd_mom_gamma.argmax()]\n",
    "gd_mom_delta_opt = delta[gd_mom_delta.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.07800000000000001 0.275 0.95 0.021652041391109985\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.05 0.95 0.02133296044271596\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.05600000000000001 0.5 0.95 0.021785460768874502\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.07800000000000001 0.5 0.825 0.021477614360114722\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.05600000000000001 0.5 0.825 0.021019447572645084\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.3875 0.825 0.021388274421771533\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.1 0.1625 0.95 0.020464675705762006\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.07800000000000001 0.5 0.95 0.019724491537328897\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.07800000000000001 0.5 0.825 0.021978492226441507\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.5 0.95 0.021101020098713567\n"
     ]
    }
   ],
   "source": [
    "trials = 10\n",
    "\n",
    "# parameters\n",
    "gamma = np.linspace(0.001, 0.1, 10)\n",
    "delta = np.linspace(0.05, 0.5, 5)\n",
    "eta = np.linspace(0.7, 0.95, 3)\n",
    "batch_size = np.arange(50, len(X_train), 50)\n",
    "\n",
    "sgd_mom_gamma = np.zeros(len(gamma))\n",
    "sgd_mom_delta = np.zeros(len(delta))\n",
    "sgd_mom_eta = np.zeros(len(eta))\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "# minibatch sgd with momentum and learning schedule\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros((len(gamma), len(delta), len(eta), len(batch_size)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            for h in range(len(eta)):\n",
    "                for b in range(len(batch_size)):\n",
    "                    model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=gamma[i], delta_momentum=delta[j], learning_rate_decay_flag=True, learning_rate_decay=eta[h], batch_size=batch_size[b])\n",
    "                    scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "                    pred_train = model.predict(X_train)\n",
    "                    train_score[i, j, h, b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l, m, n=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l, m, n])\n",
    "    sgd_mom_gamma[i_min[0]] += 1\n",
    "    sgd_mom_delta[i_min[1]] += 1\n",
    "    sgd_mom_eta[i_min[2]] += 1\n",
    "    sgd_mom_batchsize[i_min[3]] += 1\n",
    "\n",
    "    print(\"sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], eta[i_min[2]], min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_mom_gamma_opt = gamma[sgd_mom_gamma.argmax()]\n",
    "sgd_mom_delta_opt = delta[sgd_mom_delta.argmax()]\n",
    "sgd_mom_eta_opt = eta[sgd_mom_eta.argmax()]\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.19220425837946933\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "55 0.19220426023675682\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.19220425883127062\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1922042575055339\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1922042573207149\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.19220426356636414\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.19220425925588405\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.19220425691727347\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.19220425713879302\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1922042583487819\n"
     ]
    }
   ],
   "source": [
    "# iterating over different batch sizes again\n",
    "# since the grid search above resulted in the smallest possible batch size performing the best, we test for lower values of the batch size\n",
    "\n",
    "batch_size = np.arange(15, 75, 10)\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=sgd_mom_gamma_opt, delta_momentum=sgd_mom_delta_opt, learning_rate_decay_flag=True, learning_rate_decay=sgd_mom_eta_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_mom_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gd_gamma_opt' (float64)\n",
      "Stored 'gd_mom_gamma_opt' (float64)\n",
      "Stored 'sgd_mom_gamma_opt' (float64)\n",
      "Stored 'gd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_eta_opt' (float64)\n",
      "Stored 'sgd_mom_batchsize_opt' (int64)\n"
     ]
    }
   ],
   "source": [
    "# storing the optimal parameters\n",
    "%store gd_gamma_opt\n",
    "%store gd_mom_gamma_opt\n",
    "%store sgd_mom_gamma_opt\n",
    "%store gd_mom_delta_opt\n",
    "%store sgd_mom_delta_opt\n",
    "%store sgd_mom_eta_opt\n",
    "%store sgd_mom_batchsize_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2085220476302492\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.4990548441463926\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.3870432741514932\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.26023795909132935\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2948245035450071\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19944632128347944\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21106404888831723\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.20212834558655748\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2545491645558134\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.22077881929849288\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.25516452020942115\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3135825761868059\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2148554773105451\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.27389149490847\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2480048044982081\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.19549538339210928\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19686058252724123\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.36509107940893176\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.43401756086589216\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22857904751812147\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.22102118732705478\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.28993933379473624\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2673645254831603\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2882321166558153\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.22422612965661642\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.237844869246069\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.27742942472517207\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.21757096856500893\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2728776289869602\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2780912109018311\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2410446124306795\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.22219141027437966\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.1964470264710275\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.22032470250198513\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.28059890312428815\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.6822473522184977\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.27377531060752597\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.3217436642052355\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.22468273691866003\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2906417046188821\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.19220501201984203\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.23130817325545755\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.37420552629860926\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.23084610161854668\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.19266350779705893\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2222379231006238\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.4045565189190504\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.404817813410463\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2820746403190504\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.5604241983784153\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2584752926140659\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.23901911923605193\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.20174921921021866\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.22395051348372244\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2630612666549724\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2503801978767212\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.1990465450432365\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3580701070683915\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.4580044940139382\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2070198191564716\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.26582504584563404\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.1990472448313846\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.28891249206516306\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.20417097046858254\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.30778307467447397\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2770189786420936\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.5763332584851372\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.19695016292470366\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.19756395865642784\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.39408700180553297\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2576529468234837\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2810426178738834\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.27178274366483945\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.33146431548146776\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19282438328771004\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.3443288492276472\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2306659410073781\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2618983671079859\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.4956997096347079\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2366291047924549\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2191810038672921\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.20482977872248406\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.26178987877861837\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.6034652377394203\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2377048912384635\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21737179068133997\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.23217689626746973\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.414842608994129\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2905356647839871\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.26472285969720044\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21582382954842425\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.25138648947889464\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.23575182872293776\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.23451048079722633\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.4479402442684486\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.26672314024660726\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.362030918005421\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21889323097090008\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.19758854081303864\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.19598887591194483\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "batch_size = np.arange(50, len(X_train), 50)\n",
    "\n",
    "sgd_adam_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"adam\", learning_rate=sgd_mom_gamma_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_adam_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_adam_batchsize_opt = batch_size[sgd_adam_batchsize.argmax()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
