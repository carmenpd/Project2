{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import arange\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from func_autograd import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def MSE(y_data, y_model):\n",
    "\tn = np.size(y_model)\n",
    "\ty_data = y_data.reshape(-1,1)\n",
    "\ty_model = y_model.reshape(-1,1)\n",
    "\treturn np.sum((y_data - y_model)**2)/n\n",
    "\n",
    "\n",
    "def generate_data(noise=True, step_size=0.05 , FrankesFunction=True):\n",
    "    # Arrange x and y\n",
    "    x = np.arange(0, 1, step_size)\n",
    "    y = np.arange(0, 1, step_size)\n",
    "    # Create meshgrid of x and y\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    if FrankesFunction:\n",
    "        # Calculate the values for Franke function\n",
    "        z = FrankeFunction(X, Y, noise=noise).flatten()\n",
    "    else:\n",
    "        z = TestFunction(X, Y, noise=noise).flatten()\n",
    "\n",
    "    # Flatten x and y for plotting\n",
    "    x = X.flatten()\n",
    "    y = Y.flatten()\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "def TestFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "\n",
    "    return  x**2 + y**2 + 2*x*y + random_noise\n",
    "\n",
    "def FrankeFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "    \n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + random_noise\n",
    "\n",
    "x, y, z = generate_data()\n",
    "X = create_X(x, y, 7)\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd: learning rate and minimal train MSE\n",
      "0.034 0.25410182611689397\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.023000000000000003 0.5 0.1859358547250422\n",
      "gd: learning rate and minimal train MSE\n",
      "0.05600000000000001 0.2637819219939614\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.034 0.5 0.18558961193919588\n",
      "gd: learning rate and minimal train MSE\n",
      "0.034 0.24995105107762294\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.001 0.2 0.19152873358995057\n",
      "gd: learning rate and minimal train MSE\n",
      "0.023000000000000003 0.18909703930585292\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.1 0.5 0.18551231311513394\n",
      "gd: learning rate and minimal train MSE\n",
      "0.1 0.19251560041866905\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.05600000000000001 0.35000000000000003 0.18623938160379816\n",
      "gd: learning rate and minimal train MSE\n",
      "0.034 0.25077354630634974\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.012 0.25 0.18597938597860753\n",
      "gd: learning rate and minimal train MSE\n",
      "0.05600000000000001 0.2575636214280026\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.067 0.35000000000000003 0.19560561854168634\n",
      "gd: learning rate and minimal train MSE\n",
      "0.07800000000000001 0.1989016148244721\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.05600000000000001 0.1 0.1857073450159674\n",
      "gd: learning rate and minimal train MSE\n",
      "0.067 0.2399052381696183\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.07800000000000001 0.2 0.18617211873599535\n",
      "gd: learning rate and minimal train MSE\n",
      "0.023000000000000003 0.20441748873057594\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.034 0.2 0.19819410658199846\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "gamma = np.linspace(0.001, 0.1, 10)\n",
    "delta = np.linspace(0.05, 0.5, 10)\n",
    "eta = np.linspace(0.7, 0.95, 5)\n",
    "\n",
    "X_train = X_train[:, 1:3]\n",
    "X_test = X_test[:, 1:3]\n",
    "\n",
    "trials = 10\n",
    "\n",
    "gd_gamma = np.zeros(len(gamma))\n",
    "gd_mom_gamma = np.zeros(len(gamma))\n",
    "gd_mom_delta = np.zeros(len(delta))\n",
    "\n",
    "for t in range(trials):\n",
    "    initial_val = np.random.randn(X_train.shape[1],1)\n",
    "\n",
    "    # plain gradient descent\n",
    "    train_score = np.zeros(len(gamma))\n",
    "    for i in range(len(gamma)):\n",
    "        model = GradientDescend(momentum=False, learning_rate=gamma[i])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[i] = MSE(pred_train, z_train)\n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    gd_gamma[i_min] += 1\n",
    "    print(\"gd: learning rate and minimal train MSE\")\n",
    "    print(gamma[i_min], min)\n",
    "\n",
    "    # adding momentum\n",
    "    train_score = np.zeros((len(gamma), len(delta)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            model = GradientDescend(learning_rate=gamma[i], delta_momentum=delta[j])\n",
    "            scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "            pred_train = model.predict(X_train)\n",
    "            train_score[i, j] = MSE(pred_train, z_train)\n",
    "        \n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l])\n",
    "    gd_mom_gamma[i_min[0]] += 1\n",
    "    gd_mom_delta[i_min[1]] += 1\n",
    "    print(\"gd with momentum: learning rate, momentum and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], min)\n",
    "\n",
    "\n",
    "gd_gamma_opt = gamma[gd_gamma.argmax()]\n",
    "gd_mom_gamma_opt = gamma[gd_mom_gamma.argmax()]\n",
    "gd_mom_delta_opt = delta[gd_mom_delta.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.1 0.5 0.95 0.18521939965504275\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.3875 0.95 0.18521939973425258\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.1 0.05 0.95 0.1852193997604058\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.07800000000000001 0.3875 0.95 0.18521940006739598\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.5 0.95 0.18521940010381002\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.067 0.5 0.95 0.18521940003268023\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.1 0.3875 0.95 0.18521939973959461\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.275 0.95 0.18521939986645564\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.1 0.1625 0.95 0.18521939970714874\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.08900000000000001 0.3875 0.95 0.1852193997412198\n"
     ]
    }
   ],
   "source": [
    "trials = 10\n",
    "\n",
    "# parameters\n",
    "gamma = np.linspace(0.001, 0.1, 10)\n",
    "delta = np.linspace(0.05, 0.5, 5)\n",
    "eta = np.linspace(0.7, 0.95, 3)\n",
    "batch_size = np.arange(50, len(X_train), 50)\n",
    "\n",
    "sgd_mom_gamma = np.zeros(len(gamma))\n",
    "sgd_mom_delta = np.zeros(len(delta))\n",
    "sgd_mom_eta = np.zeros(len(eta))\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "# minibatch sgd with momentum and learning schedule\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros((len(gamma), len(delta), len(eta), len(batch_size)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            for h in range(len(eta)):\n",
    "                for b in range(len(batch_size)):\n",
    "                    model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=gamma[i], delta_momentum=delta[j], learning_rate_decay_flag=True, learning_rate_decay=eta[h], batch_size=batch_size[b])\n",
    "                    scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "                    pred_train = model.predict(X_train)\n",
    "                    train_score[i, j, h, b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l, m, n=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l, m, n])\n",
    "    sgd_mom_gamma[i_min[0]] += 1\n",
    "    sgd_mom_delta[i_min[1]] += 1\n",
    "    sgd_mom_eta[i_min[2]] += 1\n",
    "    sgd_mom_batchsize[i_min[3]] += 1\n",
    "\n",
    "    print(\"sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], eta[i_min[2]], min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_mom_gamma_opt = gamma[sgd_mom_gamma.argmax()]\n",
    "sgd_mom_delta_opt = delta[sgd_mom_delta.argmax()]\n",
    "sgd_mom_eta_opt = eta[sgd_mom_eta.argmax()]\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.18521940199032041\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.1852194006121435\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.1852193998811053\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1852194009388542\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1852194017756509\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.1852194020041773\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.18521940122604083\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.18521940086311417\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "15 0.1852194024095446\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "25 0.1852194013784381\n"
     ]
    }
   ],
   "source": [
    "# iterating over different batch sizes again\n",
    "# since the grid search above resulted in the smallest possible batch size performing the best, we test for lower values of the batch size\n",
    "\n",
    "batch_size = np.arange(15, 75, 10)\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=sgd_mom_gamma_opt, delta_momentum=sgd_mom_delta_opt, learning_rate_decay_flag=True, learning_rate_decay=sgd_mom_eta_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_mom_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gd_gamma_opt' (float64)\n",
      "Stored 'gd_mom_gamma_opt' (float64)\n",
      "Stored 'sgd_mom_gamma_opt' (float64)\n",
      "Stored 'gd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_eta_opt' (float64)\n",
      "Stored 'sgd_mom_batchsize_opt' (int64)\n"
     ]
    }
   ],
   "source": [
    "# storing the optimal parameters\n",
    "%store gd_gamma_opt\n",
    "%store gd_mom_gamma_opt\n",
    "%store sgd_mom_gamma_opt\n",
    "%store gd_mom_delta_opt\n",
    "%store sgd_mom_delta_opt\n",
    "%store sgd_mom_eta_opt\n",
    "%store sgd_mom_batchsize_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2028953236689804\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.23879798217837483\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2300712488028853\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2526853529110344\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.43247193752536256\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.26299985843941254\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.19972012850169288\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.37396484620101483\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.24008858827283916\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19689708354308597\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.21792363272117116\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.37976010989616354\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.487425692520551\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.20505709654906898\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.36374611565552256\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2211207243607301\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2232667008101035\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.5149011660015974\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.20939889708479067\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.1901289692361253\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.29185937837931475\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.24863142401286661\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3575884051704643\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.29482058387788806\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.39475724844947974\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2719270914792894\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.21590420779940936\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.5557097689999555\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.21784563256482697\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.35836409325255375\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2430094703038682\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.20907866396855218\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.32027502382331086\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2191969120857894\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.5955184765576519\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2222282521741146\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.25920933924716666\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2638750443014471\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.21669399286273158\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.21873603615390125\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.5043633078610751\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.49724363469105676\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.1940036490170533\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.21759430851829673\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.25112216495647494\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.26578086058196576\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.271601103350571\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.22888838091484967\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.18672069395309526\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.36787004003601254\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22806860128599893\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.24663255028993053\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.41114884683629904\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.28977523126659416\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.34184651506584524\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.39020500709721556\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2529939268186764\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.22682592425335613\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.26549500659518055\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.3478037719745299\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.21279157859809478\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.34329022935614617\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.281246601828891\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.3826903438637343\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22715181565971054\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2254020936829417\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.35401999677225227\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.26461387946409903\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2298904759934815\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.45464664120367293\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.20126507532466348\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3383830736076344\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2651670071057905\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2053669415019269\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2554868847629572\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.30547276858063344\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21675510568752973\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.23564111795774884\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.42081099753035434\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.23307294472347412\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.5019273551701661\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.26166741396742577\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2370291515825295\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.18809574243796792\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.5678923767859678\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.21664938013586274\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.36515266025292625\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.33469399851555187\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.297255148841683\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2393001998192318\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.28908754669038655\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19863120281213403\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.22341592865656532\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.25751981954073994\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2600892898088478\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.20288064698043867\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.19003732825212866\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.244294849646792\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.31504715192100413\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.42604306534132697\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "batch_size = np.arange(50, len(X_train), 50)\n",
    "\n",
    "sgd_adam_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"adam\", learning_rate=sgd_mom_gamma_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_adam_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_adam_batchsize_opt = batch_size[sgd_adam_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'sgd_adam_batchsize_opt' (int64)\n"
     ]
    }
   ],
   "source": [
    "%store sgd_adam_batchsize_opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
