{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import arange\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from func_autograd import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def MSE(y_data, y_model):\n",
    "\tn = np.size(y_model)\n",
    "\ty_data = y_data.reshape(-1,1)\n",
    "\ty_model = y_model.reshape(-1,1)\n",
    "\treturn np.sum((y_data - y_model)**2)/n\n",
    "\n",
    "\n",
    "def generate_data(noise=True, step_size=0.05 , FrankesFunction=True):\n",
    "    # Arrange x and y\n",
    "    x = np.arange(0, 1, step_size)\n",
    "    y = np.arange(0, 1, step_size)\n",
    "    # Create meshgrid of x and y\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    if FrankesFunction:\n",
    "        # Calculate the values for Franke function\n",
    "        z = FrankeFunction(X, Y, noise=noise).flatten()\n",
    "    else:\n",
    "        z = TestFunction(X, Y, noise=noise).flatten()\n",
    "\n",
    "    # Flatten x and y for plotting\n",
    "    x = X.flatten()\n",
    "    y = Y.flatten()\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "def TestFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "\n",
    "    return  x**2 + y**2 + 2*x*y + random_noise\n",
    "\n",
    "def FrankeFunction(x, y, noise=False):\n",
    "    if noise: \n",
    "        random_noise = np.random.normal(0, 0.1 , x.shape)\n",
    "    else: \n",
    "        random_noise = 0\n",
    "    \n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + random_noise\n",
    "\n",
    "x, y, z = generate_data()\n",
    "X = create_X(x, y, 7)\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters GD\n",
    "trials = 10\n",
    "\n",
    "gamma = np.linspace(0.01, 0.13, 7)\n",
    "delta = np.linspace(0.6, 1, 7)\n",
    "eta = np.linspace(0.9, 0.999, 5)\n",
    "batch_size = np.arange(10, 50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd: learning rate and minimal train MSE\n",
      "0.01 0.2863758610694571\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.03 0.8666666666666667 0.2120873032357589\n",
      "gd: learning rate and minimal train MSE\n",
      "0.09 0.22176743384087502\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.05 0.6666666666666666 0.19393262597249009\n",
      "gd: learning rate and minimal train MSE\n",
      "0.05 0.24385173298825374\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.01 0.9333333333333333 0.20514091483236238\n",
      "gd: learning rate and minimal train MSE\n",
      "0.11 0.19322159143780693\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.13 1.0 0.19313378686619076\n",
      "gd: learning rate and minimal train MSE\n",
      "0.09 0.3382354761410309\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.13 0.9333333333333333 0.19465612959365095\n",
      "gd: learning rate and minimal train MSE\n",
      "0.05 0.4127567597132159\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.11 0.9333333333333333 0.24445082911032556\n",
      "gd: learning rate and minimal train MSE\n",
      "0.06999999999999999 0.22806886341563473\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.11 1.0 0.19602668480027424\n",
      "gd: learning rate and minimal train MSE\n",
      "0.03 0.23335365172247435\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.11 0.6 0.199270574976994\n",
      "gd: learning rate and minimal train MSE\n",
      "0.03 0.403020223221607\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.01 0.9333333333333333 0.19532469731106464\n",
      "gd: learning rate and minimal train MSE\n",
      "0.13 0.20733999474192752\n",
      "gd with momentum: learning rate, momentum and minimal train MSE\n",
      "0.06999999999999999 0.6666666666666666 0.22304824939377885\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:, 1:3]\n",
    "X_test = X_test[:, 1:3]\n",
    "\n",
    "gd_gamma = np.zeros(len(gamma))\n",
    "gd_mom_gamma = np.zeros(len(gamma))\n",
    "gd_mom_delta = np.zeros(len(delta))\n",
    "\n",
    "for t in range(trials):\n",
    "    \n",
    "    # plain gradient descent\n",
    "    train_score = np.zeros(len(gamma))\n",
    "    for i in range(len(gamma)):\n",
    "        model = GradientDescend(momentum=False, learning_rate=gamma[i])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[i] = MSE(pred_train, z_train)\n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    gd_gamma[i_min] += 1\n",
    "    print(\"gd: learning rate and minimal train MSE\")\n",
    "    print(gamma[i_min], min)\n",
    "\n",
    "    # adding momentum\n",
    "    train_score = np.zeros((len(gamma), len(delta)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            model = GradientDescend(learning_rate=gamma[i], delta_momentum=delta[j])\n",
    "            scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "            pred_train = model.predict(X_train)\n",
    "            train_score[i, j] = MSE(pred_train, z_train)\n",
    "        \n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l])\n",
    "    gd_mom_gamma[i_min[0]] += 1\n",
    "    gd_mom_delta[i_min[1]] += 1\n",
    "    print(\"gd with momentum: learning rate, momentum and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], min)\n",
    "\n",
    "\n",
    "gd_gamma_opt = gamma[gd_gamma.argmax()]\n",
    "gd_mom_gamma_opt = gamma[gd_mom_gamma.argmax()]\n",
    "gd_mom_delta_opt = delta[gd_mom_delta.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.05 0.7333333333333333 0.9742500000000001 0.19182313305870666\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.05 0.8666666666666667 0.9742500000000001 0.1918231330596769\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.11 0.8 0.9742500000000001 0.19182313306013377\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.11 0.7333333333333333 0.9742500000000001 0.19182313306095455\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.11 0.9333333333333333 0.9742500000000001 0.19182313305904775\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.03 0.9333333333333333 0.9742500000000001 0.19182313306017537\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.09 0.6 0.9742500000000001 0.19182313306130594\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.03 0.6666666666666666 0.9742500000000001 0.19182313306028856\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.13 0.9333333333333333 0.9742500000000001 0.1918231330597505\n",
      "sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\n",
      "0.06999999999999999 0.6666666666666666 0.9742500000000001 0.19182313305984242\n"
     ]
    }
   ],
   "source": [
    "# minibatch sgd with momentum and learning schedule\n",
    "sgd_mom_gamma = np.zeros(len(gamma))\n",
    "sgd_mom_delta = np.zeros(len(delta))\n",
    "sgd_mom_eta = np.zeros(len(eta))\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros((len(gamma), len(delta), len(eta), len(batch_size)))\n",
    "    for j in range(len(delta)):\n",
    "        for i in range(len(gamma)):\n",
    "            for h in range(len(eta)):\n",
    "                for b in range(len(batch_size)):\n",
    "                    model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=gamma[i], delta_momentum=delta[j], learning_rate_decay_flag=True, learning_rate_decay=eta[h], batch_size=batch_size[b])\n",
    "                    scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "                    pred_train = model.predict(X_train)\n",
    "                    train_score[i, j, h, b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    k, l, m, n=np.shape(train_score)\n",
    "    i_min = np.unravel_index(i_min, shape=[k, l, m, n])\n",
    "    sgd_mom_gamma[i_min[0]] += 1\n",
    "    sgd_mom_delta[i_min[1]] += 1\n",
    "    sgd_mom_eta[i_min[2]] += 1\n",
    "    sgd_mom_batchsize[i_min[3]] += 1\n",
    "\n",
    "    print(\"sgd with momentum: learning rate, momentum, learning rate decay and minimal train MSE\")\n",
    "    print(gamma[i_min[0]], delta[i_min[1]], eta[i_min[2]], min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_mom_gamma_opt = gamma[sgd_mom_gamma.argmax()]\n",
    "sgd_mom_delta_opt = delta[sgd_mom_delta.argmax()]\n",
    "sgd_mom_eta_opt = eta[sgd_mom_eta.argmax()]\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterating over different batch sizes again\n",
    "# since the grid search above resulted in the smallest possible batch size performing the best, we test for lower values of the batch size\n",
    "\n",
    "sgd_mom_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"gd\", learning_rate=sgd_mom_gamma_opt, delta_momentum=sgd_mom_delta_opt, learning_rate_decay_flag=True, learning_rate_decay=sgd_mom_eta_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_mom_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_mom_batchsize_opt = batch_size[sgd_mom_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 100\n",
    "batch_size = np.arange(50, len(X_train), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2244975467003096\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21330132671042373\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.3107925740275043\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.4034309187208384\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.20316900648946515\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2549536895803511\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22573655585188376\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.4096458113871427\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2428556488878947\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.4350071577246852\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2766847504487155\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.39538378569564986\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.23116178968447015\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19900005084353659\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.8212393569027618\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.35671828647909626\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.21473935673871258\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.3144754026505509\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.20083810420201192\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.23454710459339911\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.29058560247748255\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.21535927127399687\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.22464977526987012\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.4862250923839802\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.38423164063703424\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.7706474637779991\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.506696893971775\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22070157098542723\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.3031536374846526\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.32324346555924693\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2981568821064821\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2173057161065173\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.39280129386500534\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2239101624507571\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.31929140367777387\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2935492048194399\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.20332114134916968\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2032999147437709\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.23105872050197335\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2388966110075782\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3452273119606111\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.1949351880262454\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.9015318597993051\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.19672876001866002\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2167870877558115\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2490624731270641\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.19614361533610353\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.3048365652766798\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2934187819431711\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.29439446099891514\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.4559208941131709\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2491539643278845\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.21471451903414396\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.6257716725988628\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.22066903807721228\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.24759881547489135\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2932072662153404\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.537316521918947\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2410211903557791\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2667199717177311\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.21243167646319816\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.21075324848615448\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.229096068050509\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.22484891902020337\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.20829837199183307\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.39722910117144394\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2034965113221028\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.24699981596820664\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2516066805529596\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.34769467335006526\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.21380120619344475\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2915709112836219\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.2226431413277462\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.2860230857462484\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.27021934814239673\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.23334148867611282\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.31204131795957407\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2650995516317412\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19745671019680475\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.20044434740473047\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.3393152193529764\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.19249007748470107\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2325288766772823\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2446133222089004\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.2670724971588016\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.2959360263631004\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.25039534871119484\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.2084877469122836\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.25555374808852976\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.4203397591546304\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.34665915883634185\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.34539618554209406\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "150 0.29077183404365525\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "100 0.20654284103043868\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.22630975729681396\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "250 0.5594164368264986\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.23440264576371087\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.3375487394159049\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "200 0.35950729996021463\n",
      "sgd with momentum: batch size and minimal train MSE\n",
      "50 0.20396924397209687\n"
     ]
    }
   ],
   "source": [
    "sgd_adam_batchsize = np.zeros(len(batch_size))\n",
    "\n",
    "for t in range(trials):\n",
    "    train_score = np.zeros(len(batch_size))\n",
    "    for b in range(len(batch_size)):\n",
    "        model = GradientDescend(optimizer=\"sgd\", method=\"adam\", learning_rate=sgd_mom_gamma_opt, batch_size=batch_size[b])\n",
    "        scores = model.fit(X_train, z_train, X_test, z_test)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        train_score[b] = MSE(pred_train, z_train)\n",
    "                \n",
    "\n",
    "    i_min, min = train_score.argmin(), train_score.min()\n",
    "    sgd_adam_batchsize[i_min] += 1\n",
    "\n",
    "    print(\"sgd with momentum: batch size and minimal train MSE\")\n",
    "    print(batch_size[i_min], min)\n",
    "\n",
    "\n",
    "sgd_adam_batchsize_opt = batch_size[sgd_adam_batchsize.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gd_gamma_opt' (float64)\n",
      "Stored 'gd_mom_gamma_opt' (float64)\n",
      "Stored 'sgd_mom_gamma_opt' (float64)\n",
      "Stored 'gd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_delta_opt' (float64)\n",
      "Stored 'sgd_mom_eta_opt' (float64)\n",
      "Stored 'sgd_mom_batchsize_opt' (int64)\n",
      "Stored 'sgd_adam_batchsize_opt' (int64)\n"
     ]
    }
   ],
   "source": [
    "# storing the optimal parameters\n",
    "%store gd_gamma_opt\n",
    "%store gd_mom_gamma_opt\n",
    "%store sgd_mom_gamma_opt\n",
    "%store gd_mom_delta_opt\n",
    "%store sgd_mom_delta_opt\n",
    "%store sgd_mom_eta_opt\n",
    "%store sgd_mom_batchsize_opt\n",
    "%store sgd_adam_batchsize_opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
